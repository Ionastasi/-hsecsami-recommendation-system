{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Демонстрация работы классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы находимся в папке <code>./source<code>, все данные находятся в папке <code>./data<code>. Помимо прочего, там содержатся txt-файлы распарсенных статей и файл с отметками некоторых статей. Перед тем, как обучать на них классификатор, полезно превратить эти статьи в мешки слов, причем постараться избавиться от словоформ.\n",
    "\n",
    "За это отвественнен модуль <code>normalizing<code>. Он берет множество распарсенных статей, множество статей с отметками и \"нормализует\" их, то есть превращает в мешок слов те статьи, которые еще не нормализованы.\n",
    "\n",
    "У normalizing есть два режима, в которых он по-разному составляет мешки слов. По умолчанию это режим, когда просто ищутся все вхождения слов регуляркой <code>'\\w+[\\-\\w+]*'<code> и потом с помощью pymorphy2 отсеиваются служебные части речи: местоимения, предлоги, союзы, частицы, междометия. Оставшиеся слова приводятся к нормальной форме с помощью той же библиотеки и записываются в мешок слов.\n",
    "\n",
    "Второй режим можно включить ключом --empirical. У него более сложные регулярки и чуть более сложная система проверок, которые просто показались мне логичными, но не имеют никакого серьезного обоснования (отсюда и название). Сразу отсекаются русские слова короче 4 символов и английские короче 2. Слова вроде 'android-гаджет' раскладываются в два слова. Оставшиеся слова аналогично приводятся к нормальной форме и заносятся в мешок слов.\n",
    "\n",
    "Помимо прочего, мы отдельно нормализуем и сохраняем в разные файлы заголовки и сам текст статьи. В дальнейшем мы будет на них независимо обучаться.\n",
    "\n",
    "Для начала отчистим старые мешки слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! python3 normalizing.py --clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим новые мешки слов (дефолтный режим)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python3 normalizing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера, вот так выглядит мешок слов для статьи <link>https://geektimes.ru/company/payonline/blog/272648/<link>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "автомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineконец\r\n",
      "февраль\r\n",
      "visa\r\n",
      "представить\r\n",
      "необычный\r\n",
      "платёжный\r\n",
      "решение\r\n",
      "приложение\r\n",
      "который\r\n",
      "помочь\r\n",
      "водитель\r\n",
      "оплачивать\r\n",
      "бензин\r\n",
      "заправка\r\n",
      "выходить\r\n",
      "машина\r\n",
      "visa\r\n",
      "honda\r\n",
      "объединиться\r\n",
      "воплотить\r\n",
      "жизнь\r\n",
      "новое\r\n",
      "платёжный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "презентация\r\n",
      "который\r\n",
      "состояться\r\n",
      "mobile\r\n",
      "world\r\n",
      "congress\r\n",
      "барселона\r\n",
      "позволять\r\n",
      "оплачивать\r\n",
      "парковка\r\n",
      "заправка\r\n",
      "автомобиль\r\n",
      "выходить\r\n",
      "план\r\n",
      "разработка\r\n",
      "подобный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "visa\r\n",
      "заявить\r\n",
      "год\r\n",
      "назад\r\n",
      "visa\r\n",
      "honda\r\n",
      "создать\r\n",
      "приложение\r\n",
      "который\r\n",
      "пользоваться\r\n",
      "непосредственно\r\n",
      "панель\r\n",
      "управление\r\n",
      "автомобиль\r\n",
      "сообщать\r\n",
      "водитель\r\n",
      "низок\r\n",
      "уровень\r\n",
      "топливо\r\n",
      "строить\r\n",
      "маршрут\r\n",
      "ближний\r\n",
      "заправка\r\n",
      "машина\r\n",
      "парковаться\r\n",
      "возле\r\n",
      "топливный\r\n",
      "насос\r\n",
      "приложение\r\n",
      "рассчитывать\r\n",
      "стоимость\r\n",
      "заправка\r\n",
      "предлагать\r\n",
      "совершить\r\n",
      "оплата\r\n",
      "прямо\r\n",
      "панель\r\n",
      "управление\r\n",
      "visa\r\n",
      "предполагать\r\n",
      "дать\r\n",
      "технология\r\n",
      "огромный\r\n",
      "потенциал\r\n",
      "уже\r\n",
      "четыре\r\n",
      "год\r\n",
      "миллиард\r\n",
      "автомобиль\r\n",
      "быть\r\n",
      "подключить"
     ]
    }
   ],
   "source": [
    "!cat ../data/normalized/272648.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к собственно обучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Мы будем использовать три классификатора и сравнивать их работу. Введем их: создадим для каждого свой pipeline и парметры для grid search-а."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd, multi_nb, bernoulli_nb = ClassifierData(), ClassifierData(), ClassifierData()\n",
    "sgd.name = 'SGDClassifier'\n",
    "multi_nb.name = 'MultinomialNB'\n",
    "bernoulli_nb.name = 'BernoulliNB'\n",
    "sgd.clf = Pipeline([('cnt', TfidfVectorizer()),\n",
    "                    ('clf', SGDClassifier(loss='log'))\n",
    "                    ])\n",
    "multi_nb.clf = Pipeline([('cnt', TfidfVectorizer()),\n",
    "                         ('clf', MultinomialNB())\n",
    "                        ])\n",
    "bernoulli_nb.clf = Pipeline([('cnt', CountVectorizer()),\n",
    "                             ('clf', BernoulliNB(binarize=0.0))\n",
    "                            ])\n",
    "sgd.parameters = {'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                  'clf__l1_ratio': [0.0, 0.01, 0.05, 0.10, 0.2, 0.3, 0.4, 0.5],\n",
    "                  'clf__alpha': [0.001, 0.0001, 0.00001, 0.000001, 0.0000001],\n",
    "                  'cnt__use_idf': (True, False),\n",
    "                 }\n",
    "multi_nb.parameters = {'clf__alpha': [0.001, 0.0001, 0.00001, 0.000001, 0.0000001],\n",
    "                       'cnt__use_idf': (True, False),\n",
    "                      }\n",
    "bernoulli_nb.parameters = {'clf__alpha': [0.001, 0.0001, 0.00001, 0.000001, 0.0000001],\n",
    "                          }\n",
    "all_classifiers = [sgd, multi_nb, bernoulli_nb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим тестовую и тренировочную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 41\n"
     ]
    }
   ],
   "source": [
    "full_struct = get_a_structures(test_part=0.2)\n",
    "train, test = full_struct.train, full_struct.test\n",
    "print(len(train.data), len(test.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестовой выборки отбиралось по 0.2 от всех элементов каждого класса. Если посмотреть на цифры, то будет следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train positive: 68\n",
      "train negative: 91\n",
      "test positive: 18\n",
      "test negative: 23\n"
     ]
    }
   ],
   "source": [
    "print(\"train positive:\", train.target.count(1))\n",
    "print(\"train negative:\", train.target.count(-1))\n",
    "print(\"test positive:\", test.target.count(1))\n",
    "print(\"test negative:\", test.target.count(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Плохих\" статей несколько больше. Но что уж тут поделать.\n",
    "\n",
    "Переходя к обучению, рассмотрим следующую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def choose_the_classifier(classifiers_to_check, data, target):\n",
    "    best_classifier = None\n",
    "    best_score = 0;\n",
    "    best_name = ''\n",
    "    for cur_classifier in classifiers_to_check:\n",
    "        log.debug('Now training ' + cur_classifier.name)\n",
    "        searcher = GridSearchCV(estimator=cur_classifier.clf,\n",
    "                                param_grid=cur_classifier.parameters,\n",
    "                                scoring=scorer,\n",
    "                                cv=3,\n",
    "                                n_jobs=-1\n",
    "                                )\n",
    "        t = time()\n",
    "        searcher.fit(data, target)\n",
    "        t = time() - t\n",
    "        log.debug(\"{} min, {} sec\".format(int(t // 60), round(t % 60, 3)))\n",
    "        cur_best_score = searcher.best_score_\n",
    "        log.debug(\"best score (auc): {}\".format(round(cur_best_score, 3)))\n",
    "        log.debug(\"best parameters: {}\".format(searcher.best_params_))\n",
    "        if cur_best_score > best_score:\n",
    "            best_score = cur_best_score\n",
    "            best_classifier = searcher.best_estimator_\n",
    "            best_name = cur_classifier.name\n",
    "    return BestClassifier(clf=best_classifier, name=best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она принимает на вход лист классификаторов (те самые, которые мы вводили в самом начале) и тренировочную выборку, data и target.\n",
    "\n",
    "Для каждого классификатора создается свой Grid Search (в качестве scorer выбран auc) с ранее определенными параметрами и, собственно, обучается. Среди всех классификаторов выбирается тот, который показал наилучший результат.\n",
    "\n",
    "Соответственно, эту функцию мы сейчас будем использовать. Для начала, обучимся на заголовках статей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... 4.651 sec\n",
      "best for titles: SGDClassifier\n"
     ]
    }
   ],
   "source": [
    "print(\"Training... \", end ='')\n",
    "t = time()\n",
    "best_titles_clf = choose_the_classifier(all_classifiers, train.titles, train.target) \n",
    "print(round(time() - t, 3), \"sec\")\n",
    "print(\"best for titles:\", best_titles_clf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заголовки штуки короткие, так что обучение происходит быстро.\n",
    "\n",
    "Перед тем как переходить к обучению на непосредественно текстах статей, добавим в параметры каждого классификатора еще несколько полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in all_classifiers:\n",
    "    clf.parameters['cnt__max_df'] = [0.85, 0.9, 0.95, 1.0]\n",
    "    clf.parameters['cnt__min_df'] = [0.01, 0.05, 0.10, 0.15, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже говорилось, заголовки короткие, поэтому попытка ограничивать их по df почти всегда приводит к пустой выборке. Поэтому эти параметры мы добавляем только сейчас.\n",
    "\n",
    "И вот, начинаем обучать классификаторы для текстов. Они длиннее, количество параметров для сетки увеличилось, так что это займет уже на порядок больше времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... 17 min, 35.89 sec\n",
      "best for text: MultinomialNB\n"
     ]
    }
   ],
   "source": [
    "print(\"Training... \", end ='')\n",
    "t = time()\n",
    "best_texts_clf = choose_the_classifier(all_classifiers, train.data, train.target) \n",
    "t = time() - t\n",
    "print(\"{} min, {} sec\".format(int(t // 60), round(t % 60, 3)))\n",
    "print(\"best for text:\", best_texts_clf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь самое время проверить результат на тестовой выборке!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.691\n",
      "confusion matrix:\n",
      " [[17  6]\n",
      " [10  8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.63      0.74      0.68        23\n",
      "   Positive       0.57      0.44      0.50        18\n",
      "\n",
      "avg / total       0.60      0.61      0.60        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_titles = best_titles_clf.clf.predict_proba(test.titles)\n",
    "pred_texts = best_texts_clf.clf.predict_proba(test.data)\n",
    "predicted_proba = list()\n",
    "predicted_target = list()\n",
    "for i in range(len(test.data)):\n",
    "    prob_neg = 0.5 * (pred_titles[i][0] + pred_texts[i][0])\n",
    "    prob_pos = 0.5 * (pred_titles[i][1] + pred_texts[i][1])\n",
    "    predicted_proba.append(prob_pos)\n",
    "    if prob_neg > prob_pos:\n",
    "        predicted_target.append(-1)\n",
    "    else:\n",
    "        predicted_target.append(1)\n",
    "\n",
    "\n",
    "print(\"auc:\", round(metrics.roc_auc_score(test.target, predicted_proba), 3))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(test.target, predicted_target))\n",
    "print(metrics.classification_report(test.target, predicted_target,\n",
    "                                    target_names=test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот такой резульатат на тестовой выборке мы получаем. В целом, довольно неплохо.\n",
    "\n",
    "Теперь вернемся в самое начало и вспомним, что у нас есть еще один способ составления мешка слов. Проверим, какой результат будет для него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! python3 normalizing.py --clean\n",
    "! python3 normalizing.py --empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на том же примере, как выглядит мешок слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "автомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineавтомобиль\r\n",
      "оплата\r\n",
      "nfc\r\n",
      "автоматизация\r\n",
      "технология\r\n",
      "visa\r\n",
      "honda\r\n",
      "payonlineконец\r\n",
      "февраль\r\n",
      "visa\r\n",
      "представить\r\n",
      "необычный\r\n",
      "платёжный\r\n",
      "решение\r\n",
      "приложение\r\n",
      "который\r\n",
      "помочь\r\n",
      "водитель\r\n",
      "оплачивать\r\n",
      "бензин\r\n",
      "заправка\r\n",
      "выходить\r\n",
      "машина\r\n",
      "visa\r\n",
      "honda\r\n",
      "объединиться\r\n",
      "чтобы\r\n",
      "воплотить\r\n",
      "жизнь\r\n",
      "новое\r\n",
      "платёжный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "презентация\r\n",
      "который\r\n",
      "состояться\r\n",
      "mobile\r\n",
      "world\r\n",
      "congress\r\n",
      "барселона\r\n",
      "позволять\r\n",
      "оплачивать\r\n",
      "парковка\r\n",
      "заправка\r\n",
      "автомобиль\r\n",
      "выходить\r\n",
      "план\r\n",
      "разработка\r\n",
      "подобный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "visa\r\n",
      "заявить\r\n",
      "назад\r\n",
      "visa\r\n",
      "honda\r\n",
      "создать\r\n",
      "приложение\r\n",
      "который\r\n",
      "можно\r\n",
      "пользоваться\r\n",
      "непосредственно\r\n",
      "панель\r\n",
      "управление\r\n",
      "автомобиль\r\n",
      "сообщать\r\n",
      "водитель\r\n",
      "низок\r\n",
      "уровень\r\n",
      "топливо\r\n",
      "строить\r\n",
      "маршрут\r\n",
      "ближний\r\n",
      "заправка\r\n",
      "когда\r\n",
      "машина\r\n",
      "парковаться\r\n",
      "возле\r\n",
      "топливный\r\n",
      "насос\r\n",
      "приложение\r\n",
      "рассчитывать\r\n",
      "стоимость\r\n",
      "заправка\r\n",
      "предлагать\r\n",
      "совершить\r\n",
      "оплата\r\n",
      "прямо\r\n",
      "через\r\n",
      "панель\r\n",
      "управление\r\n",
      "visa\r\n",
      "предполагать\r\n",
      "дать\r\n",
      "технология\r\n",
      "есть\r\n",
      "огромный\r\n",
      "потенциал\r\n",
      "через\r\n",
      "четыре\r\n",
      "около\r\n",
      "миллиард\r\n",
      "автомобиль\r\n",
      "быть\r\n",
      "подключить"
     ]
    }
   ],
   "source": [
    "! cat ../data/normalized/272648.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторяем все предыдущие действия. Но не забываем для заголовков настроить границы df на дефолтные, в противном случае вылетим с ошибкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with titles... 4.578 sec\n",
      "best for titles: SGDClassifier\n",
      "Training with texts... 17 min, 24.524 sec\n",
      "best for texts: MultinomialNB\n",
      "auc: 0.664\n",
      "confusion matrix:\n",
      " [[18  5]\n",
      " [ 8 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.69      0.78      0.73        23\n",
      "   Positive       0.67      0.56      0.61        18\n",
      "\n",
      "avg / total       0.68      0.68      0.68        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_struct = get_a_structures(test_part=0.2)\n",
    "train, test = full_struct.train, full_struct.test\n",
    "\n",
    "print(\"Training with titles... \", end ='')\n",
    "for clf in all_classifiers:\n",
    "    clf.parameters['cnt__max_df'] = [1.0]\n",
    "    clf.parameters['cnt__min_df'] = [1]\n",
    "t = time()\n",
    "best_titles_clf = choose_the_classifier(all_classifiers, train.titles, train.target) \n",
    "print(round(time() - t, 3), \"sec\")\n",
    "print(\"best for titles:\", best_titles_clf.name)\n",
    "\n",
    "print(\"Training with texts... \", end ='')\n",
    "for clf in all_classifiers:\n",
    "    clf.parameters['cnt__max_df'] = [0.85, 0.9, 0.95, 1.0]\n",
    "    clf.parameters['cnt__min_df'] = [0.01, 0.05, 0.10, 0.15, 1]\n",
    "t = time()\n",
    "best_texts_clf = choose_the_classifier(all_classifiers, train.data, train.target) \n",
    "t = time() - t\n",
    "print(\"{} min, {} sec\".format(int(t // 60), round(t % 60, 3)))\n",
    "print(\"best for texts:\", best_texts_clf.name)\n",
    "\n",
    "pred_titles = best_titles_clf.clf.predict_proba(test.titles)\n",
    "pred_texts = best_texts_clf.clf.predict_proba(test.data)\n",
    "predicted_proba = list()\n",
    "predicted_target = list()\n",
    "for i in range(len(test.data)):\n",
    "    prob_neg = 0.5 * (pred_titles[i][0] + pred_texts[i][0])\n",
    "    prob_pos = 0.5 * (pred_titles[i][1] + pred_texts[i][1])\n",
    "    predicted_proba.append(prob_pos)\n",
    "    if prob_neg > prob_pos:\n",
    "        predicted_target.append(-1)\n",
    "    else:\n",
    "        predicted_target.append(1)\n",
    "\n",
    "\n",
    "print(\"auc:\", round(metrics.roc_auc_score(test.target, predicted_proba), 3))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(test.target, predicted_target))\n",
    "print(metrics.classification_report(test.target, predicted_target,\n",
    "                                    target_names=test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод показал более плохой результат на тестовой выборке, если смотреть на auc, но более хороший, если смотреть accuracy.\n",
    "\n",
    "Любопытно, что оба метода выбрали одинаковые классификаторы для заголовков и одинаковые для текстов.\n",
    "\n",
    "Вообще, главная моя проблема --- это очень маленькая выборка. В зависимости от того, как исходно были перемешанные размеченные данные и с чего в итоге состоят тестовая и тренировочная выборка, может сильно зависеть результат.\n",
    "\n",
    "Что посмотреть, что происходит, можно просто несколько раз запустить программу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==STEP 1==\n",
      "Training... 17 min, 55.168 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: MultinomialNB\n",
      "auc: 0.705\n",
      "[[14  9]\n",
      " [ 8 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.64      0.61      0.62        23\n",
      "   Positive       0.53      0.56      0.54        18\n",
      "\n",
      "avg / total       0.59      0.59      0.59        41\n",
      "\n",
      "==STEP 2==\n",
      "Training... 17 min, 53.75 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: MultinomialNB\n",
      "auc: 0.727\n",
      "[[17  6]\n",
      " [ 7 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.71      0.74      0.72        23\n",
      "   Positive       0.65      0.61      0.63        18\n",
      "\n",
      "avg / total       0.68      0.68      0.68        41\n",
      "\n",
      "==STEP 3==\n",
      "Training... 15 min, 35.794 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: SGDClassifier\n",
      "auc: 0.725\n",
      "[[14  9]\n",
      " [ 8 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.64      0.61      0.62        23\n",
      "   Positive       0.53      0.56      0.54        18\n",
      "\n",
      "avg / total       0.59      0.59      0.59        41\n",
      "\n",
      "==AVERAGE SCORE==\n",
      "0.719\n"
     ]
    }
   ],
   "source": [
    "! python3 classifier.py --steps=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути говоря, мы просто три раза запускаем программу. Каждое новое обучение происходит совершенно независимо от предыдущего. Цель данной демонстрации --- показать, какая стабильность у полученного результата.\n",
    "\n",
    "Сейчас, напомню, был \"эмпирический\" режим составления мешков слов. Посмотрим теперь, что будет в \"дефолтном\" режиме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python3 normalizing.py --clean\n",
    "! python3 normalizing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==STEP 1==\n",
      "Training... 17 min, 17.395 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: MultinomialNB\n",
      "auc: 0.688\n",
      "[[17  6]\n",
      " [ 8 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.68      0.74      0.71        23\n",
      "   Positive       0.62      0.56      0.59        18\n",
      "\n",
      "avg / total       0.66      0.66      0.66        41\n",
      "\n",
      "==STEP 2==\n",
      "Training... 17 min, 38.743 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: MultinomialNB\n",
      "auc: 0.713\n",
      "[[18  5]\n",
      " [11  7]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.62      0.78      0.69        23\n",
      "   Positive       0.58      0.39      0.47        18\n",
      "\n",
      "avg / total       0.60      0.61      0.59        41\n",
      "\n",
      "==STEP 3==\n",
      "Training... 18 min, 3.167 sec\n",
      "\n",
      "PREDICTED QUALITY\n",
      "best for titles: SGDClassifier\n",
      "best for text: SGDClassifier\n",
      "auc: 0.729\n",
      "[[19  4]\n",
      " [11  7]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.63      0.83      0.72        23\n",
      "   Positive       0.64      0.39      0.48        18\n",
      "\n",
      "avg / total       0.63      0.63      0.61        41\n",
      "\n",
      "==AVERAGE SCORE==\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "! python3 classifier.py --steps=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что разброс не очень сильный (но скорее всго это потому, что не успела пронать большое количество раз). Но если мы посмотрим, какие результаты получилась в первых демонстрациях, то увидим, что там они были все-таки несколько ниже -- то есть тут уже можно заметить эффект маленькой выборки."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
