{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Демонстрация работы классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы находимся в папке <code>./source<code>, все данные находятся в папке <code>./data<code>. Помимо прочего, там содержатся txt-файлы распарсенных статей и файл с отметками некоторых статей. Перед тем, как обучать на них классификатор, полезно превратить эти статьи в мешки слов, причем постараться избавиться от словоформ.\n",
    "\n",
    "За это отвественнен модуль <code>normalizing<code>. Он берет множество распарсенных статей, множество статей с отметками и \"нормализует\" их, то есть превращает в мешок слов те статьи, которые еще не нормализованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 273408 normalized\n",
      "Post 272936 normalized\n",
      "Post 272922 normalized\n",
      "Post 273992 normalized\n",
      "Post 272948 normalized\n"
     ]
    }
   ],
   "source": [
    "import normalizing\n",
    "\n",
    "normalizing.normalizing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас программа обработала только пять статей, остальные были обработаны ранее.\n",
    "\n",
    "Для примера, вот так выглядит мешок слов для статьи <link>https://geektimes.ru/company/payonline/blog/272648/<link>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "конец\r\n",
      "февраль\r\n",
      "visa\r\n",
      "представить\r\n",
      "необычный\r\n",
      "платёжный\r\n",
      "решение\r\n",
      "приложение\r\n",
      "который\r\n",
      "помочь\r\n",
      "водитель\r\n",
      "оплачивать\r\n",
      "бензин\r\n",
      "заправка\r\n",
      "выходить\r\n",
      "машина\r\n",
      "visa\r\n",
      "honda\r\n",
      "объединиться\r\n",
      "чтобы\r\n",
      "воплотить\r\n",
      "жизнь\r\n",
      "новое\r\n",
      "платёжный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "презентация\r\n",
      "который\r\n",
      "состояться\r\n",
      "mobile\r\n",
      "world\r\n",
      "congress\r\n",
      "барселона\r\n",
      "позволять\r\n",
      "оплачивать\r\n",
      "парковка\r\n",
      "заправка\r\n",
      "автомобиль\r\n",
      "выходить\r\n",
      "план\r\n",
      "разработка\r\n",
      "подобный\r\n",
      "приложение\r\n",
      "автомобиль\r\n",
      "visa\r\n",
      "заявить\r\n",
      "назад\r\n",
      "visa\r\n",
      "honda\r\n",
      "создать\r\n",
      "приложение\r\n",
      "который\r\n",
      "можно\r\n",
      "пользоваться\r\n",
      "непосредственно\r\n",
      "панель\r\n",
      "управление\r\n",
      "автомобиль\r\n",
      "сообщать\r\n",
      "водитель\r\n",
      "низок\r\n",
      "уровень\r\n",
      "топливо\r\n",
      "строить\r\n",
      "маршрут\r\n",
      "ближний\r\n",
      "заправка\r\n",
      "когда\r\n",
      "машина\r\n",
      "парковаться\r\n",
      "возле\r\n",
      "топливный\r\n",
      "насос\r\n",
      "приложение\r\n",
      "рассчитывать\r\n",
      "стоимость\r\n",
      "заправка\r\n",
      "предлагать\r\n",
      "совершить\r\n",
      "оплата\r\n",
      "прямо\r\n",
      "через\r\n",
      "панель\r\n",
      "управление\r\n",
      "visa\r\n",
      "предполагать\r\n",
      "дать\r\n",
      "технология\r\n",
      "есть\r\n",
      "огромный\r\n",
      "потенциал\r\n",
      "через\r\n",
      "четыре\r\n",
      "около\r\n",
      "миллиард\r\n",
      "автомобиль\r\n",
      "быть\r\n",
      "подключить"
     ]
    }
   ],
   "source": [
    "!cat ../data/normalized_text/272648.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к собственно обучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим выборку для обучения и тренировки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 61\n"
     ]
    }
   ],
   "source": [
    "full_struct = get_a_structures(test_part=0.3)\n",
    "train, test = full_struct.train, full_struct.test\n",
    "print(len(train.data), len(test.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестовой выборки отбиралось по 0.3 от всех элементов каждого класса. Если посмотреть на цифры, то будет следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train positive: 60\n",
      "train negative: 79\n",
      "test positive: 26\n",
      "test negative: 35\n"
     ]
    }
   ],
   "source": [
    "print(\"train positive:\", train.target.count(1))\n",
    "print(\"train negative:\", train.target.count(-1))\n",
    "print(\"test positive:\", test.target.count(1))\n",
    "print(\"test negative:\", test.target.count(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Плохих\" статей несколько больше. Но что уж тут поделать.\n",
    "\n",
    "Для удобства создадим <code>Papeline<code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='log'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>CountVectorizer<code> с помощью своего внутреннего словаря заодно отсеит всякие мусорные слова английского языка, что представляется довольно удобным. В качестве классификатора использует линейную регрессию с стохастическим градиентным спуском. Выборка для обучения разбивается на 5 частей.\n",
    "\n",
    "Некоторые остальные параметры будет подбирать с помощью Gread Search-а. В качестве метрики для выбора наилучших параметров (<code>scorer<code>) будет auc-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "def scorer(estimator, X, Y):\n",
    "    metric = metrics.roc_auc_score\n",
    "    return metric(Y, estimator.predict_proba(X)[:, 1])\n",
    "\n",
    "parameters = {'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "              'clf__l1_ratio': [0.0, 0.01, 0.05],\n",
    "              'clf__alpha': [0.001, 0.0001],\n",
    "              'tfidf__use_idf': (True, False)\n",
    "             }\n",
    "\n",
    "searcher = GridSearchCV(estimator=text_clf,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scorer,\n",
    "                        cv=5,\n",
    "                        n_jobs=-1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, собственно, запустим тренироваться на наших данных..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... 11.563 sec\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "print('Training... ', end='')\n",
    "t = time()\n",
    "searcher.fit(train.data, train.target)\n",
    "print(round(time() - t, 3), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно узнать, каких результатов добилась наша сетка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (auc): 0.843\n",
      "best parameters:\n",
      "{'tfidf__use_idf': True, 'clf__penalty': 'l2', 'clf__alpha': 0.0001, 'clf__l1_ratio': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(\"best score (auc):\", round(searcher.best_score_, 3))\n",
    "print(\"best parameters:\", searcher.best_params_, sep='\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь самое время проверить результат на тестовой выборке!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.636\n",
      "mean: 0.639\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.67      0.74      0.70        35\n",
      "   Positive       0.59      0.50      0.54        26\n",
      "\n",
      "avg / total       0.63      0.64      0.63        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_cls = searcher.best_estimator_\n",
    "predicted = best_cls.predict(test.data)\n",
    "print(\"auc:\", round(scorer(best_cls, test.data, test.target), 3))\n",
    "print(\"mean:\", round(np.mean(predicted == test.target), 3))\n",
    "print(metrics.classification_report(test.target, predicted,\n",
    "                                    target_names=test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мне очень нравится следующая матрица: она показывает в абсолютной величне, сколько было верно угаданных элементов класса, а также сколько было ошибок первого и второго рода.\n",
    "\n",
    "(1, 1) --- верно угаданные элементы из класса -1.\n",
    "\n",
    "(2, 2) --- верно угаданные элементы из класса 1.\n",
    "\n",
    "(1, 2) и (2, 1) --- ошибки первого и второго рода.\n",
    "\n",
    "Глядя на эту матрицу, становится ясно, что классификатор очень часто считает, что статья \"плохая\". Это может быть связано с тем, что этих примеров у нас больше в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  9]\n",
      " [13 13]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, вот результат. Он, на самом деле, не то чтобы очень хороший... Предположительно, стоит использовать какую-нибудь другую метрику, или накидать больше \"хороших\" статей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
